{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place for a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression of a... (Phase Three Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem/Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What factors are most relevant to determining whether a private passenger vehicle crash in Chicago incurs property damage over $1,500? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and create new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "df_vehicles = pd.read_csv(\"Data\\Traffic_Crashes_-_Vehicles_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)\n",
    "df_people = pd.read_csv(\"Data\\Traffic_Crashes_-_People_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)\n",
    "df_crashes = pd.read_csv(\"Data\\Traffic_Crashes_-_Crashes_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any data from before 2021\n",
    "\n",
    "df_crashes = df_crashes[df_crashes[\"CRASH_DATE\"].dt.year >= 2021]\n",
    "df_people = df_people[df_people[\"CRASH_DATE\"].dt.year >= 2021]\n",
    "df_vehicles = df_vehicles[df_vehicles[\"CRASH_DATE\"].dt.year >= 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data dictionaries to understand column names, we are dropping columns from each set that are not relevant to the business problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from Vehicles dataframe\n",
    "\n",
    "df_vehicles.drop(columns = ['TOWED_I', 'FIRE_I', 'TOWED_BY', 'TOWED_TO', 'CMV_ID', \n",
    "                        'USDOT_NO', 'CCMC_NO', 'ILCC_NO', 'COMMERCIAL_SRC', 'GVWR', \n",
    "                        'CARRIER_NAME', 'CARRIER_STATE', 'CARRIER_CITY',\n",
    "                        'HAZMAT_PLACARDS_I', 'HAZMAT_NAME', 'UN_NO', 'HAZMAT_PRESENT_I', \n",
    "                        'HAZMAT_REPORT_I', 'HAZMAT_REPORT_NO', 'MCS_REPORT_I',\n",
    "                        'MCS_REPORT_NO', 'HAZMAT_VIO_CAUSE_CRASH_I', 'MCS_VIO_CAUSE_CRASH_I', \n",
    "                        'IDOT_PERMIT_NO', 'WIDE_LOAD_I', 'TRAILER1_WIDTH', 'TRAILER2_WIDTH', \n",
    "                        'TRAILER1_LENGTH', 'TRAILER2_LENGTH', 'TOTAL_VEHICLE_LENGTH',\n",
    "                        'AXLE_CNT', 'VEHICLE_CONFIG', 'CARGO_BODY_TYPE', 'LOAD_TYPE',\n",
    "                        'HAZMAT_OUT_OF_SERVICE_I', 'MCS_OUT_OF_SERVICE_I', 'HAZMAT_CLASS'],\n",
    "                         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from People dataframe\n",
    "\n",
    "df_people.drop(columns = ['HOSPITAL', 'EMS_AGENCY', 'EMS_RUN_NO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from Crashes dataframe\n",
    "\n",
    "df_crashes.drop(columns = ['REPORT_TYPE', 'DATE_POLICE_NOTIFIED', 'PHOTOS_TAKEN_I',\n",
    "                       'STATEMENTS_TAKEN_I', 'DOORING_I', 'INJURIES_TOTAL', \n",
    "                       'INJURIES_FATAL', 'INJURIES_INCAPACITATING', \n",
    "                       'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT', \n",
    "                       'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are most interested in vehicle damage, we are using the Vehicles dataframe as the main and merging the others into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge People dataframe with Vehicles dataframe\n",
    "\n",
    "df = df_vehicles.merge(df_people, how=\"left\", on=[\"CRASH_RECORD_ID\", \"CRASH_DATE\", \"RD_NO\", \"VEHICLE_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Crashes dataframe with merged dataframe\n",
    "\n",
    "df = pd.merge(df, df_crashes, how = 'inner', on = ['CRASH_RECORD_ID', \"CRASH_DATE\", \"RD_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting new dataframe to csv for use throughout rest of notebook\n",
    "\n",
    "df.to_csv(\"Data\\chicago_traffic_accidents_2021_to_11-09-2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a single merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can load merged dataframe without needing to go through above steps each time\n",
    "df = pd.read_csv(\"Data\\chicago_traffic_accidents_2021_to_11-09-2023.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want unique vehicle damage count, so we need to remove rows that represent passengers, as these will duplicate the vehicle damage. We also should remove any other rows that don't represent drivers. We can use the \"PERSON_TYPE\" column for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRIVER                 0.780694\n",
       "PASSENGER              0.197756\n",
       "PEDESTRIAN             0.012899\n",
       "BICYCLE                0.007730\n",
       "NON-MOTOR VEHICLE      0.000760\n",
       "NON-CONTACT VEHICLE    0.000162\n",
       "Name: PERSON_TYPE, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values in Person_type column\n",
    "\n",
    "df['PERSON_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all types of person except DRIVER\n",
    "\n",
    "df = df[df['PERSON_TYPE'] == 'DRIVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRIVER    1.0\n",
       "Name: PERSON_TYPE, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df['PERSON_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at null values to try to determine which columns might need to be imputed or if the data is too incomplete to be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First dropping columns that no longer have any data after removing all but DRIVER entries\n",
    "\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 530319 entries, 0 to 766594\n",
      "Data columns (total 89 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Unnamed: 0               530319 non-null  int64  \n",
      " 1   CRASH_UNIT_ID            530319 non-null  int64  \n",
      " 2   CRASH_RECORD_ID          530319 non-null  object \n",
      " 3   RD_NO                    522422 non-null  object \n",
      " 4   CRASH_DATE               530319 non-null  object \n",
      " 5   UNIT_NO                  530319 non-null  int64  \n",
      " 6   UNIT_TYPE                530310 non-null  object \n",
      " 7   NUM_PASSENGERS           85079 non-null   float64\n",
      " 8   VEHICLE_ID               530098 non-null  float64\n",
      " 9   CMRC_VEH_I               10945 non-null   object \n",
      " 10  MAKE                     530098 non-null  object \n",
      " 11  MODEL                    530098 non-null  object \n",
      " 12  LIC_PLATE_STATE          469533 non-null  object \n",
      " 13  VEHICLE_YEAR             434488 non-null  float64\n",
      " 14  VEHICLE_DEFECT           530098 non-null  object \n",
      " 15  VEHICLE_TYPE             530098 non-null  object \n",
      " 16  VEHICLE_USE              530098 non-null  object \n",
      " 17  TRAVEL_DIRECTION         530098 non-null  object \n",
      " 18  MANEUVER                 530098 non-null  object \n",
      " 19  OCCUPANT_CNT             530098 non-null  float64\n",
      " 20  EXCEED_SPEED_LIMIT_I     9 non-null       object \n",
      " 21  AREA_00_I                16553 non-null   object \n",
      " 22  AREA_01_I                159444 non-null  object \n",
      " 23  AREA_02_I                79273 non-null   object \n",
      " 24  AREA_03_I                53585 non-null   object \n",
      " 25  AREA_04_I                46911 non-null   object \n",
      " 26  AREA_05_I                72099 non-null   object \n",
      " 27  AREA_06_I                82203 non-null   object \n",
      " 28  AREA_07_I                71300 non-null   object \n",
      " 29  AREA_08_I                41432 non-null   object \n",
      " 30  AREA_09_I                45306 non-null   object \n",
      " 31  AREA_10_I                72690 non-null   object \n",
      " 32  AREA_11_I                155461 non-null  object \n",
      " 33  AREA_12_I                163782 non-null  object \n",
      " 34  AREA_99_I                76331 non-null   object \n",
      " 35  FIRST_CONTACT_POINT      529973 non-null  object \n",
      " 36  PERSON_ID                530319 non-null  object \n",
      " 37  PERSON_TYPE              530319 non-null  object \n",
      " 38  CITY                     391147 non-null  object \n",
      " 39  STATE                    387258 non-null  object \n",
      " 40  ZIPCODE                  365479 non-null  object \n",
      " 41  SEX                      530319 non-null  object \n",
      " 42  AGE                      377472 non-null  float64\n",
      " 43  DRIVERS_LICENSE_STATE    390210 non-null  object \n",
      " 44  DRIVERS_LICENSE_CLASS    308207 non-null  object \n",
      " 45  SAFETY_EQUIPMENT         530319 non-null  object \n",
      " 46  AIRBAG_DEPLOYED          530319 non-null  object \n",
      " 47  EJECTION                 530319 non-null  object \n",
      " 48  INJURY_CLASSIFICATION    530319 non-null  object \n",
      " 49  DRIVER_ACTION            530319 non-null  object \n",
      " 50  DRIVER_VISION            530319 non-null  object \n",
      " 51  PHYSICAL_CONDITION       530319 non-null  object \n",
      " 52  BAC_RESULT               530319 non-null  object \n",
      " 53  BAC_RESULT VALUE         612 non-null     float64\n",
      " 54  CELL_PHONE_USE           2 non-null       object \n",
      " 55  CRASH_DATE_EST_I         32074 non-null   object \n",
      " 56  POSTED_SPEED_LIMIT       530319 non-null  int64  \n",
      " 57  TRAFFIC_CONTROL_DEVICE   530319 non-null  object \n",
      " 58  DEVICE_CONDITION         530319 non-null  object \n",
      " 59  WEATHER_CONDITION        530319 non-null  object \n",
      " 60  LIGHTING_CONDITION       530319 non-null  object \n",
      " 61  FIRST_CRASH_TYPE         530319 non-null  object \n",
      " 62  TRAFFICWAY_TYPE          530319 non-null  object \n",
      " 63  LANE_CNT                 71 non-null      float64\n",
      " 64  ALIGNMENT                530319 non-null  object \n",
      " 65  ROADWAY_SURFACE_COND     530319 non-null  object \n",
      " 66  ROAD_DEFECT              530319 non-null  object \n",
      " 67  CRASH_TYPE               530319 non-null  object \n",
      " 68  INTERSECTION_RELATED_I   142097 non-null  object \n",
      " 69  NOT_RIGHT_OF_WAY_I       18683 non-null   object \n",
      " 70  HIT_AND_RUN_I            166473 non-null  object \n",
      " 71  DAMAGE                   530319 non-null  object \n",
      " 72  PRIM_CONTRIBUTORY_CAUSE  530319 non-null  object \n",
      " 73  SEC_CONTRIBUTORY_CAUSE   530319 non-null  object \n",
      " 74  STREET_NO                530319 non-null  int64  \n",
      " 75  STREET_DIRECTION         530317 non-null  object \n",
      " 76  STREET_NAME              530319 non-null  object \n",
      " 77  BEAT_OF_OCCURRENCE       530319 non-null  float64\n",
      " 78  WORK_ZONE_I              2425 non-null    object \n",
      " 79  WORK_ZONE_TYPE           1821 non-null    object \n",
      " 80  WORKERS_PRESENT_I        678 non-null     object \n",
      " 81  NUM_UNITS                530319 non-null  int64  \n",
      " 82  MOST_SEVERE_INJURY       530319 non-null  object \n",
      " 83  CRASH_HOUR               530319 non-null  int64  \n",
      " 84  CRASH_DAY_OF_WEEK        530319 non-null  int64  \n",
      " 85  CRASH_MONTH              530319 non-null  int64  \n",
      " 86  LATITUDE                 525675 non-null  float64\n",
      " 87  LONGITUDE                525675 non-null  float64\n",
      " 88  LOCATION                 525675 non-null  object \n",
      "dtypes: float64(10), int64(9), object(70)\n",
      "memory usage: 364.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the total nulls left in remaining columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns that seem useful from the data dictionaries, but look almost entirely full of nulls. We do a value_counts for those columns to see what's in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     445240\n",
       "1.0      60610\n",
       "2.0      15374\n",
       "3.0       6037\n",
       "4.0       2034\n",
       "5.0        560\n",
       "6.0        234\n",
       "7.0         84\n",
       "8.0         28\n",
       "10.0        23\n",
       "9.0         19\n",
       "11.0        18\n",
       "12.0        10\n",
       "17.0         6\n",
       "14.0         5\n",
       "19.0         4\n",
       "13.0         4\n",
       "16.0         4\n",
       "15.0         3\n",
       "18.0         2\n",
       "22.0         2\n",
       "21.0         2\n",
       "27.0         2\n",
       "43.0         2\n",
       "26.0         2\n",
       "20.0         1\n",
       "33.0         1\n",
       "34.0         1\n",
       "28.0         1\n",
       "46.0         1\n",
       "42.0         1\n",
       "30.0         1\n",
       "32.0         1\n",
       "31.0         1\n",
       "24.0         1\n",
       "Name: NUM_PASSENGERS, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUM_PASSENGERS\n",
    "\n",
    "df[\"NUM_PASSENGERS\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no 0 value, so we will cross check with the OCCUPANT_CNT column and impute 0 where OCCUPANT_CNT = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    519374\n",
       "Y        6602\n",
       "N        4343\n",
       "Name: CMRC_VEH_I, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CMRC_VEH_I\n",
    "\n",
    "df[\"CMRC_VEH_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We can drop the Y rows because they are commercial vehicles and do not fit the business problem, but the rest we will leave as we cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    530310\n",
       "N           5\n",
       "Y           4\n",
       "Name: EXCEED_SPEED_LIMIT_I, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXCEED_SPEED_LIMIT_I\n",
    "\n",
    "df[\"EXCEED_SPEED_LIMIT_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column for our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      152847\n",
       "28.0      10881\n",
       "27.0      10830\n",
       "29.0      10759\n",
       "26.0      10716\n",
       "          ...  \n",
       "101.0         5\n",
       "102.0         4\n",
       "103.0         3\n",
       "98.0          3\n",
       "110.0         2\n",
       "Name: AGE, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AGE\n",
    "\n",
    "df[\"AGE\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values is a smaller percentage, so we can impute based on the average age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.979439534587996"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"AGE\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST NOT OFFERED                   522875\n",
       "TEST REFUSED                         5377\n",
       "TEST PERFORMED, RESULTS UNKNOWN      1197\n",
       "TEST TAKEN                            870\n",
       "Name: BAC_RESULT, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAC_RESULT for BAC_RESULT VALUE\n",
    "\n",
    "df[\"BAC_RESULT\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nulls. We could create a binary flag feature as TESTED_FOR_BAC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    530317\n",
       "N           2\n",
       "Name: CELL_PHONE_USE, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL_PHONE_USE\n",
    "\n",
    "df[\"CELL_PHONE_USE\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column for our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    530248\n",
       "2.0        25\n",
       "4.0        21\n",
       "1.0         7\n",
       "3.0         7\n",
       "6.0         4\n",
       "5.0         4\n",
       "0.0         2\n",
       "8.0         1\n",
       "Name: LANE_CNT, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LANE_CNT\n",
    "\n",
    "df[\"LANE_CNT\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the ratio is representative of the whole. This does not seem to be a useful column for our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    388222\n",
       "Y      135705\n",
       "N        6392\n",
       "Name: INTERSECTION_RELATED_I, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INTERSECTION_RELATED_I\n",
    "\n",
    "df[\"INTERSECTION_RELATED_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the majority. We may be able to impute values to the NaN because the Y/N values are a sizeable fraction of the whole, but we may want to leave this out of our initial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    511636\n",
       "Y       16802\n",
       "N        1881\n",
       "Name: NOT_RIGHT_OF_WAY_I, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOT_RIGHT_OF_WAY_I\n",
    "\n",
    "df[\"NOT_RIGHT_OF_WAY_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column for our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    363846\n",
       "Y      159186\n",
       "N        7287\n",
       "Name: HIT_AND_RUN_I, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIT_AND_RUN_I\n",
    "\n",
    "df[\"HIT_AND_RUN_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the majority. We may be able to impute values to the NaN because the Y/N values are a sizeable fraction of the whole, but we may want to leave this out of our initial model. We could assume that N is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    527894\n",
       "Y        1821\n",
       "N         604\n",
       "Name: WORK_ZONE_I, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORK_ZONE_I \n",
    "\n",
    "df[\"WORK_ZONE_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column for our initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OVER $1,500      364244\n",
       "$501 - $1,500    121941\n",
       "$500 OR LESS      44134\n",
       "Name: DAMAGE, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values in Damage column\n",
    "\n",
    "df['DAMAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to identify damage as > $1500 or <= $1500\n",
    "\n",
    "damage_dict = {'OVER $1,500':'HIGH', '$501 - $1,500':'LOW', '$500 OR LESS':'LOW'}\n",
    "df['DAMAGE_LEVEL'] =  df.loc[:, ('DAMAGE')].map(damage_dict).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIGH    364244\n",
       "LOW     166075\n",
       "Name: DAMAGE_LEVEL, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df['DAMAGE_LEVEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to identify BAC_TEST as Y/N\n",
    "\n",
    "bac_dict = {'TEST NOT OFFERED':0, 'TEST REFUSED':1, 'TEST PERFORMED, RESULTS UNKNOWN':1, 'TEST TAKEN':1}\n",
    "df['BAC_TEST'] =  df.loc[:, ('BAC_RESULT')].map(bac_dict).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    522875\n",
       "1      7444\n",
       "Name: BAC_TEST, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df[\"BAC_TEST\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide Xs/y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRASH_UNIT_ID</th>\n",
       "      <th>UNIT_NO</th>\n",
       "      <th>NUM_PASSENGERS</th>\n",
       "      <th>VEHICLE_ID</th>\n",
       "      <th>VEHICLE_YEAR</th>\n",
       "      <th>OCCUPANT_CNT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BAC_RESULT VALUE</th>\n",
       "      <th>POSTED_SPEED_LIMIT</th>\n",
       "      <th>LANE_CNT</th>\n",
       "      <th>STREET_NO</th>\n",
       "      <th>BEAT_OF_OCCURRENCE</th>\n",
       "      <th>NUM_UNITS</th>\n",
       "      <th>CRASH_HOUR</th>\n",
       "      <th>CRASH_DAY_OF_WEEK</th>\n",
       "      <th>CRASH_MONTH</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>BAC_TEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>530319.000000</td>\n",
       "      <td>5.303190e+05</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>85079.000000</td>\n",
       "      <td>5.300980e+05</td>\n",
       "      <td>434488.000000</td>\n",
       "      <td>530098.000000</td>\n",
       "      <td>377472.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>530319.00000</td>\n",
       "      <td>530319.000000</td>\n",
       "      <td>525675.000000</td>\n",
       "      <td>525675.000000</td>\n",
       "      <td>530319.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>390142.266426</td>\n",
       "      <td>1.361133e+06</td>\n",
       "      <td>1.446550</td>\n",
       "      <td>1.461971</td>\n",
       "      <td>1.293301e+06</td>\n",
       "      <td>2014.895571</td>\n",
       "      <td>1.234123</td>\n",
       "      <td>39.979440</td>\n",
       "      <td>0.175310</td>\n",
       "      <td>28.954733</td>\n",
       "      <td>3.014085</td>\n",
       "      <td>3743.570470</td>\n",
       "      <td>1238.961751</td>\n",
       "      <td>2.089508</td>\n",
       "      <td>13.342303</td>\n",
       "      <td>4.13705</td>\n",
       "      <td>6.422097</td>\n",
       "      <td>41.852162</td>\n",
       "      <td>-87.673383</td>\n",
       "      <td>0.014037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>222517.264243</td>\n",
       "      <td>1.964298e+05</td>\n",
       "      <td>0.561206</td>\n",
       "      <td>1.024149</td>\n",
       "      <td>1.881972e+05</td>\n",
       "      <td>118.463723</td>\n",
       "      <td>0.674167</td>\n",
       "      <td>15.818965</td>\n",
       "      <td>0.105121</td>\n",
       "      <td>5.324429</td>\n",
       "      <td>1.553732</td>\n",
       "      <td>2851.585483</td>\n",
       "      <td>700.305196</td>\n",
       "      <td>0.485570</td>\n",
       "      <td>5.505126</td>\n",
       "      <td>1.97904</td>\n",
       "      <td>3.247378</td>\n",
       "      <td>0.366222</td>\n",
       "      <td>0.747839</td>\n",
       "      <td>0.117643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.017880e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.647270e+05</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-87.936193</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>195234.500000</td>\n",
       "      <td>1.191992e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.130992e+06</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>41.780034</td>\n",
       "      <td>-87.722823</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>396971.000000</td>\n",
       "      <td>1.361150e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.293444e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3264.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>41.871794</td>\n",
       "      <td>-87.675546</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>582789.500000</td>\n",
       "      <td>1.531866e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.456725e+06</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5604.000000</td>\n",
       "      <td>1814.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>41.924064</td>\n",
       "      <td>-87.633892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>766594.000000</td>\n",
       "      <td>1.699577e+06</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.617697e+06</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13799.000000</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>42.022780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  CRASH_UNIT_ID        UNIT_NO  NUM_PASSENGERS  \\\n",
       "count  530319.000000   5.303190e+05  530319.000000    85079.000000   \n",
       "mean   390142.266426   1.361133e+06       1.446550        1.461971   \n",
       "std    222517.264243   1.964298e+05       0.561206        1.024149   \n",
       "min         0.000000   1.017880e+06       1.000000        1.000000   \n",
       "25%    195234.500000   1.191992e+06       1.000000        1.000000   \n",
       "50%    396971.000000   1.361150e+06       1.000000        1.000000   \n",
       "75%    582789.500000   1.531866e+06       2.000000        2.000000   \n",
       "max    766594.000000   1.699577e+06      12.000000       46.000000   \n",
       "\n",
       "         VEHICLE_ID   VEHICLE_YEAR   OCCUPANT_CNT            AGE  \\\n",
       "count  5.300980e+05  434488.000000  530098.000000  377472.000000   \n",
       "mean   1.293301e+06    2014.895571       1.234123      39.979440   \n",
       "std    1.881972e+05     118.463723       0.674167      15.818965   \n",
       "min    9.647270e+05    1900.000000       0.000000       0.000000   \n",
       "25%    1.130992e+06    2009.000000       1.000000      27.000000   \n",
       "50%    1.293444e+06    2014.000000       1.000000      37.000000   \n",
       "75%    1.456725e+06    2018.000000       1.000000      51.000000   \n",
       "max    1.617697e+06    9999.000000      47.000000     110.000000   \n",
       "\n",
       "       BAC_RESULT VALUE  POSTED_SPEED_LIMIT   LANE_CNT      STREET_NO  \\\n",
       "count        612.000000       530319.000000  71.000000  530319.000000   \n",
       "mean           0.175310           28.954733   3.014085    3743.570470   \n",
       "std            0.105121            5.324429   1.553732    2851.585483   \n",
       "min            0.000000            0.000000   0.000000       0.000000   \n",
       "25%            0.130000           30.000000   2.000000    1329.000000   \n",
       "50%            0.180000           30.000000   3.000000    3264.000000   \n",
       "75%            0.220000           30.000000   4.000000    5604.000000   \n",
       "max            1.000000           70.000000   8.000000   13799.000000   \n",
       "\n",
       "       BEAT_OF_OCCURRENCE      NUM_UNITS     CRASH_HOUR  CRASH_DAY_OF_WEEK  \\\n",
       "count       530319.000000  530319.000000  530319.000000       530319.00000   \n",
       "mean          1238.961751       2.089508      13.342303            4.13705   \n",
       "std            700.305196       0.485570       5.505126            1.97904   \n",
       "min            111.000000       1.000000       0.000000            1.00000   \n",
       "25%            722.000000       2.000000      10.000000            2.00000   \n",
       "50%           1134.000000       2.000000      14.000000            4.00000   \n",
       "75%           1814.000000       2.000000      17.000000            6.00000   \n",
       "max           6100.000000      18.000000      23.000000            7.00000   \n",
       "\n",
       "         CRASH_MONTH       LATITUDE      LONGITUDE       BAC_TEST  \n",
       "count  530319.000000  525675.000000  525675.000000  530319.000000  \n",
       "mean        6.422097      41.852162     -87.673383       0.014037  \n",
       "std         3.247378       0.366222       0.747839       0.117643  \n",
       "min         1.000000       0.000000     -87.936193       0.000000  \n",
       "25%         4.000000      41.780034     -87.722823       0.000000  \n",
       "50%         6.000000      41.871794     -87.675546       0.000000  \n",
       "75%         9.000000      41.924064     -87.633892       0.000000  \n",
       "max        12.000000      42.022780       0.000000       1.000000  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[''] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9a3cd2e90607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\John\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4162\u001b[0m         \"\"\"\n\u001b[1;32m-> 4163\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\John\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\John\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\John\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5282\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"[''] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = df.drop(\"\", axis=1)\n",
    "y = df[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps (SS, OHE, SI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (look at Coefficients, P-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation OF/UF report Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
