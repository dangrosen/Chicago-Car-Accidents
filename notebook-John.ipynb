{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place for a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression of a... (Phase Three Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem/Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What factors from this dataset are most relevant to determining whether a private passenger vehicle crash in Chicago incurs property damage over $1,500 and can we make good predictions using these fewer factors? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and create new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "df_vehicles = pd.read_csv(\"Data\\Traffic_Crashes_-_Vehicles_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)\n",
    "df_people = pd.read_csv(\"Data\\Traffic_Crashes_-_People_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)\n",
    "df_crashes = pd.read_csv(\"Data\\Traffic_Crashes_-_Crashes_20231109.csv\", parse_dates=[\"CRASH_DATE\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any data from before 2021\n",
    "\n",
    "df_crashes = df_crashes[df_crashes[\"CRASH_DATE\"].dt.year >= 2021]\n",
    "df_people = df_people[df_people[\"CRASH_DATE\"].dt.year >= 2021]\n",
    "df_vehicles = df_vehicles[df_vehicles[\"CRASH_DATE\"].dt.year >= 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data dictionaries to understand column names, we are dropping columns from each set that are not relevant to the business problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from Vehicles dataframe\n",
    "\n",
    "df_vehicles.drop(columns = ['TOWED_I', 'FIRE_I', 'TOWED_BY', 'TOWED_TO', 'CMV_ID', \n",
    "                        'USDOT_NO', 'CCMC_NO', 'ILCC_NO', 'COMMERCIAL_SRC', 'GVWR', \n",
    "                        'CARRIER_NAME', 'CARRIER_STATE', 'CARRIER_CITY',\n",
    "                        'HAZMAT_PLACARDS_I', 'HAZMAT_NAME', 'UN_NO', 'HAZMAT_PRESENT_I', \n",
    "                        'HAZMAT_REPORT_I', 'HAZMAT_REPORT_NO', 'MCS_REPORT_I',\n",
    "                        'MCS_REPORT_NO', 'HAZMAT_VIO_CAUSE_CRASH_I', 'MCS_VIO_CAUSE_CRASH_I', \n",
    "                        'IDOT_PERMIT_NO', 'WIDE_LOAD_I', 'TRAILER1_WIDTH', 'TRAILER2_WIDTH', \n",
    "                        'TRAILER1_LENGTH', 'TRAILER2_LENGTH', 'TOTAL_VEHICLE_LENGTH',\n",
    "                        'AXLE_CNT', 'VEHICLE_CONFIG', 'CARGO_BODY_TYPE', 'LOAD_TYPE',\n",
    "                        'HAZMAT_OUT_OF_SERVICE_I', 'MCS_OUT_OF_SERVICE_I', 'HAZMAT_CLASS'],\n",
    "                         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from People dataframe\n",
    "\n",
    "df_people.drop(columns = ['HOSPITAL', 'EMS_AGENCY', 'EMS_RUN_NO'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from Crashes dataframe\n",
    "\n",
    "df_crashes.drop(columns = ['REPORT_TYPE', 'DATE_POLICE_NOTIFIED', 'PHOTOS_TAKEN_I',\n",
    "                       'STATEMENTS_TAKEN_I', 'DOORING_I', 'INJURIES_TOTAL', \n",
    "                       'INJURIES_FATAL', 'INJURIES_INCAPACITATING', \n",
    "                       'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT', \n",
    "                       'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are most interested in vehicle damage, we are using the Vehicles dataframe as the main and merging the others into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge People dataframe with Vehicles dataframe\n",
    "\n",
    "df = df_vehicles.merge(df_people, how=\"left\", on=[\"CRASH_RECORD_ID\", \"CRASH_DATE\", \"RD_NO\", \"VEHICLE_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Crashes dataframe with merged dataframe\n",
    "\n",
    "df = pd.merge(df, df_crashes, how = 'inner', on = ['CRASH_RECORD_ID', \"CRASH_DATE\", \"RD_NO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting new dataframe to csv for use throughout rest of notebook\n",
    "\n",
    "df.to_csv(\"Data\\chicago_traffic_accidents_2021_to_11-09-2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a single merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can load merged dataframe without needing to go through above steps each time\n",
    "df = pd.read_csv(\"Data\\chicago_traffic_accidents_2021_to_11-09-2023.zip\", parse_dates=[\"CRASH_DATE\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all the identifying columns as they are not useful in making a model. We will drop all of those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"CRASH_UNIT_ID\", \"CRASH_RECORD_ID\", \"RD_NO\",\n",
    "                    \"UNIT_NO\", \"VEHICLE_ID\", \"PERSON_ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want unique vehicle damage count, so we need to remove rows that represent passengers, as these will duplicate the vehicle damage. We also should remove any other rows that don't represent drivers. We can use the \"PERSON_TYPE\" column for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRIVER                 0.780694\n",
       "PASSENGER              0.197756\n",
       "PEDESTRIAN             0.012899\n",
       "BICYCLE                0.007730\n",
       "NON-MOTOR VEHICLE      0.000760\n",
       "NON-CONTACT VEHICLE    0.000162\n",
       "Name: PERSON_TYPE, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check values in Person_type column\n",
    "\n",
    "df['PERSON_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all types of person except DRIVER\n",
    "\n",
    "df = df[df['PERSON_TYPE'] == 'DRIVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRIVER    1.0\n",
       "Name: PERSON_TYPE, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df['PERSON_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at null values to try to determine which columns might need to be imputed or if the data is too incomplete to be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First dropping columns that no longer have any data after removing all but DRIVER entries\n",
    "\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 530319 entries, 0 to 766594\n",
      "Data columns (total 83 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   Unnamed: 0               530319 non-null  int64         \n",
      " 1   CRASH_DATE               530319 non-null  datetime64[ns]\n",
      " 2   UNIT_TYPE                530310 non-null  object        \n",
      " 3   NUM_PASSENGERS           85079 non-null   float64       \n",
      " 4   CMRC_VEH_I               10945 non-null   object        \n",
      " 5   MAKE                     530098 non-null  object        \n",
      " 6   MODEL                    530098 non-null  object        \n",
      " 7   LIC_PLATE_STATE          469533 non-null  object        \n",
      " 8   VEHICLE_YEAR             434488 non-null  float64       \n",
      " 9   VEHICLE_DEFECT           530098 non-null  object        \n",
      " 10  VEHICLE_TYPE             530098 non-null  object        \n",
      " 11  VEHICLE_USE              530098 non-null  object        \n",
      " 12  TRAVEL_DIRECTION         530098 non-null  object        \n",
      " 13  MANEUVER                 530098 non-null  object        \n",
      " 14  OCCUPANT_CNT             530098 non-null  float64       \n",
      " 15  EXCEED_SPEED_LIMIT_I     9 non-null       object        \n",
      " 16  AREA_00_I                16553 non-null   object        \n",
      " 17  AREA_01_I                159444 non-null  object        \n",
      " 18  AREA_02_I                79273 non-null   object        \n",
      " 19  AREA_03_I                53585 non-null   object        \n",
      " 20  AREA_04_I                46911 non-null   object        \n",
      " 21  AREA_05_I                72099 non-null   object        \n",
      " 22  AREA_06_I                82203 non-null   object        \n",
      " 23  AREA_07_I                71300 non-null   object        \n",
      " 24  AREA_08_I                41432 non-null   object        \n",
      " 25  AREA_09_I                45306 non-null   object        \n",
      " 26  AREA_10_I                72690 non-null   object        \n",
      " 27  AREA_11_I                155461 non-null  object        \n",
      " 28  AREA_12_I                163782 non-null  object        \n",
      " 29  AREA_99_I                76331 non-null   object        \n",
      " 30  FIRST_CONTACT_POINT      529973 non-null  object        \n",
      " 31  PERSON_TYPE              530319 non-null  object        \n",
      " 32  CITY                     391147 non-null  object        \n",
      " 33  STATE                    387258 non-null  object        \n",
      " 34  ZIPCODE                  365479 non-null  object        \n",
      " 35  SEX                      530319 non-null  object        \n",
      " 36  AGE                      377472 non-null  float64       \n",
      " 37  DRIVERS_LICENSE_STATE    390210 non-null  object        \n",
      " 38  DRIVERS_LICENSE_CLASS    308207 non-null  object        \n",
      " 39  SAFETY_EQUIPMENT         530319 non-null  object        \n",
      " 40  AIRBAG_DEPLOYED          530319 non-null  object        \n",
      " 41  EJECTION                 530319 non-null  object        \n",
      " 42  INJURY_CLASSIFICATION    530319 non-null  object        \n",
      " 43  DRIVER_ACTION            530319 non-null  object        \n",
      " 44  DRIVER_VISION            530319 non-null  object        \n",
      " 45  PHYSICAL_CONDITION       530319 non-null  object        \n",
      " 46  BAC_RESULT               530319 non-null  object        \n",
      " 47  BAC_RESULT VALUE         612 non-null     float64       \n",
      " 48  CELL_PHONE_USE           2 non-null       object        \n",
      " 49  CRASH_DATE_EST_I         32074 non-null   object        \n",
      " 50  POSTED_SPEED_LIMIT       530319 non-null  int64         \n",
      " 51  TRAFFIC_CONTROL_DEVICE   530319 non-null  object        \n",
      " 52  DEVICE_CONDITION         530319 non-null  object        \n",
      " 53  WEATHER_CONDITION        530319 non-null  object        \n",
      " 54  LIGHTING_CONDITION       530319 non-null  object        \n",
      " 55  FIRST_CRASH_TYPE         530319 non-null  object        \n",
      " 56  TRAFFICWAY_TYPE          530319 non-null  object        \n",
      " 57  LANE_CNT                 71 non-null      float64       \n",
      " 58  ALIGNMENT                530319 non-null  object        \n",
      " 59  ROADWAY_SURFACE_COND     530319 non-null  object        \n",
      " 60  ROAD_DEFECT              530319 non-null  object        \n",
      " 61  CRASH_TYPE               530319 non-null  object        \n",
      " 62  INTERSECTION_RELATED_I   142097 non-null  object        \n",
      " 63  NOT_RIGHT_OF_WAY_I       18683 non-null   object        \n",
      " 64  HIT_AND_RUN_I            166473 non-null  object        \n",
      " 65  DAMAGE                   530319 non-null  object        \n",
      " 66  PRIM_CONTRIBUTORY_CAUSE  530319 non-null  object        \n",
      " 67  SEC_CONTRIBUTORY_CAUSE   530319 non-null  object        \n",
      " 68  STREET_NO                530319 non-null  int64         \n",
      " 69  STREET_DIRECTION         530317 non-null  object        \n",
      " 70  STREET_NAME              530319 non-null  object        \n",
      " 71  BEAT_OF_OCCURRENCE       530319 non-null  float64       \n",
      " 72  WORK_ZONE_I              2425 non-null    object        \n",
      " 73  WORK_ZONE_TYPE           1821 non-null    object        \n",
      " 74  WORKERS_PRESENT_I        678 non-null     object        \n",
      " 75  NUM_UNITS                530319 non-null  int64         \n",
      " 76  MOST_SEVERE_INJURY       530319 non-null  object        \n",
      " 77  CRASH_HOUR               530319 non-null  int64         \n",
      " 78  CRASH_DAY_OF_WEEK        530319 non-null  int64         \n",
      " 79  CRASH_MONTH              530319 non-null  int64         \n",
      " 80  LATITUDE                 525675 non-null  float64       \n",
      " 81  LONGITUDE                525675 non-null  float64       \n",
      " 82  LOCATION                 525675 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(9), int64(7), object(66)\n",
      "memory usage: 339.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the total nulls left in remaining columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns that seem useful from the data dictionaries, but look almost entirely full of nulls. We do a value_counts for those columns to see what's in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     445240\n",
       "1.0      60610\n",
       "2.0      15374\n",
       "3.0       6037\n",
       "4.0       2034\n",
       "5.0        560\n",
       "6.0        234\n",
       "7.0         84\n",
       "8.0         28\n",
       "10.0        23\n",
       "9.0         19\n",
       "11.0        18\n",
       "12.0        10\n",
       "17.0         6\n",
       "14.0         5\n",
       "19.0         4\n",
       "13.0         4\n",
       "16.0         4\n",
       "15.0         3\n",
       "18.0         2\n",
       "22.0         2\n",
       "21.0         2\n",
       "27.0         2\n",
       "43.0         2\n",
       "26.0         2\n",
       "20.0         1\n",
       "33.0         1\n",
       "34.0         1\n",
       "28.0         1\n",
       "46.0         1\n",
       "42.0         1\n",
       "30.0         1\n",
       "32.0         1\n",
       "31.0         1\n",
       "24.0         1\n",
       "Name: NUM_PASSENGERS, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUM_PASSENGERS\n",
    "\n",
    "df[\"NUM_PASSENGERS\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no 0 value, so the NaNs are problably 0. However, OCCUPANT_CNT represents the same information so we won't need this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    519374\n",
       "Y        6602\n",
       "N        4343\n",
       "Name: CMRC_VEH_I, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CMRC_VEH_I\n",
    "\n",
    "df[\"CMRC_VEH_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We can drop the Y rows because they are commercial vehicles and do not fit the business problem, but the rest we will leave as we cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Commercial Vehicles\n",
    "\n",
    "df = df[df[\"CMRC_VEH_I\"]!=\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    519374\n",
       "N        4343\n",
       "Name: CMRC_VEH_I, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "\n",
    "df[\"CMRC_VEH_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    523708\n",
       "N           5\n",
       "Y           4\n",
       "Name: EXCEED_SPEED_LIMIT_I, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXCEED_SPEED_LIMIT_I\n",
    "\n",
    "df[\"EXCEED_SPEED_LIMIT_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      152142\n",
       "28.0      10738\n",
       "27.0      10706\n",
       "29.0      10618\n",
       "26.0      10583\n",
       "          ...  \n",
       "101.0         5\n",
       "102.0         4\n",
       "103.0         3\n",
       "98.0          3\n",
       "110.0         2\n",
       "Name: AGE, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AGE\n",
    "\n",
    "df[\"AGE\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values is a smaller percentage, so we can impute based on the average age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.92547399582857"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"AGE\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST NOT OFFERED                   516361\n",
       "TEST REFUSED                         5312\n",
       "TEST PERFORMED, RESULTS UNKNOWN      1180\n",
       "TEST TAKEN                            864\n",
       "Name: BAC_RESULT, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAC_RESULT for BAC_RESULT VALUE\n",
    "\n",
    "df[\"BAC_RESULT\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nulls. We could create a binary flag feature as TESTED_FOR_BAC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    523715\n",
       "N           2\n",
       "Name: CELL_PHONE_USE, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL_PHONE_USE\n",
    "\n",
    "df[\"CELL_PHONE_USE\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    523647\n",
       "2.0        25\n",
       "4.0        20\n",
       "1.0         7\n",
       "3.0         7\n",
       "6.0         4\n",
       "5.0         4\n",
       "0.0         2\n",
       "8.0         1\n",
       "Name: LANE_CNT, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LANE_CNT\n",
    "\n",
    "df[\"LANE_CNT\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the ratio is representative of the whole. This does not seem to be a useful column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    383355\n",
       "Y      134078\n",
       "N        6284\n",
       "Name: INTERSECTION_RELATED_I, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INTERSECTION_RELATED_I\n",
    "\n",
    "df[\"INTERSECTION_RELATED_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the majority. We may be able to impute values to the NaN because the Y/N values are a sizeable fraction of the whole, but we may want to leave this out of our initial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    505547\n",
       "Y       16342\n",
       "N        1828\n",
       "Name: NOT_RIGHT_OF_WAY_I, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOT_RIGHT_OF_WAY_I\n",
    "\n",
    "df[\"NOT_RIGHT_OF_WAY_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    358329\n",
       "Y      158154\n",
       "N        7234\n",
       "Name: HIT_AND_RUN_I, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIT_AND_RUN_I\n",
    "\n",
    "df[\"HIT_AND_RUN_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the majority. We may be able to impute values to the NaN because the Y/N values are a sizeable fraction of the whole, but we may want to leave this out of our initial model. We could assume that N is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    521390\n",
       "Y        1737\n",
       "N         590\n",
       "Name: WORK_ZONE_I, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORK_ZONE_I \n",
    "\n",
    "df[\"WORK_ZONE_I\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary flag, but the missing values represent the overwhelming majority. We cannot make an assumption from such a small subset that the Y/N ratio is representative of the whole. This does not seem to be a useful column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns determined not to be useful\n",
    "\n",
    "df.drop(columns = [\"CMRC_VEH_I\", \"EXCEED_SPEED_LIMIT_I\", \"CELL_PHONE_USE\", \n",
    "                   \"LANE_CNT\", \"NOT_RIGHT_OF_WAY_I\", \"WORK_ZONE_I\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 523717 entries, 0 to 766594\n",
      "Data columns (total 79 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   Unnamed: 0               523717 non-null  int64         \n",
      " 1   CRASH_DATE               523717 non-null  datetime64[ns]\n",
      " 2   UNIT_TYPE                523708 non-null  object        \n",
      " 3   NUM_PASSENGERS           84450 non-null   float64       \n",
      " 4   MAKE                     523496 non-null  object        \n",
      " 5   MODEL                    523496 non-null  object        \n",
      " 6   LIC_PLATE_STATE          463232 non-null  object        \n",
      " 7   VEHICLE_YEAR             428682 non-null  float64       \n",
      " 8   VEHICLE_DEFECT           523496 non-null  object        \n",
      " 9   VEHICLE_TYPE             523496 non-null  object        \n",
      " 10  VEHICLE_USE              523496 non-null  object        \n",
      " 11  TRAVEL_DIRECTION         523496 non-null  object        \n",
      " 12  MANEUVER                 523496 non-null  object        \n",
      " 13  OCCUPANT_CNT             523496 non-null  float64       \n",
      " 14  AREA_00_I                15443 non-null   object        \n",
      " 15  AREA_01_I                158378 non-null  object        \n",
      " 16  AREA_02_I                78586 non-null   object        \n",
      " 17  AREA_03_I                52985 non-null   object        \n",
      " 18  AREA_04_I                46343 non-null   object        \n",
      " 19  AREA_05_I                71250 non-null   object        \n",
      " 20  AREA_06_I                81584 non-null   object        \n",
      " 21  AREA_07_I                70493 non-null   object        \n",
      " 22  AREA_08_I                41000 non-null   object        \n",
      " 23  AREA_09_I                44908 non-null   object        \n",
      " 24  AREA_10_I                72194 non-null   object        \n",
      " 25  AREA_11_I                154610 non-null  object        \n",
      " 26  AREA_12_I                163033 non-null  object        \n",
      " 27  AREA_99_I                75719 non-null   object        \n",
      " 28  FIRST_CONTACT_POINT      523374 non-null  object        \n",
      " 29  PERSON_TYPE              523717 non-null  object        \n",
      " 30  CITY                     385181 non-null  object        \n",
      " 31  STATE                    381394 non-null  object        \n",
      " 32  ZIPCODE                  359842 non-null  object        \n",
      " 33  SEX                      523717 non-null  object        \n",
      " 34  AGE                      371575 non-null  float64       \n",
      " 35  DRIVERS_LICENSE_STATE    384260 non-null  object        \n",
      " 36  DRIVERS_LICENSE_CLASS    302924 non-null  object        \n",
      " 37  SAFETY_EQUIPMENT         523717 non-null  object        \n",
      " 38  AIRBAG_DEPLOYED          523717 non-null  object        \n",
      " 39  EJECTION                 523717 non-null  object        \n",
      " 40  INJURY_CLASSIFICATION    523717 non-null  object        \n",
      " 41  DRIVER_ACTION            523717 non-null  object        \n",
      " 42  DRIVER_VISION            523717 non-null  object        \n",
      " 43  PHYSICAL_CONDITION       523717 non-null  object        \n",
      " 44  BAC_RESULT               523717 non-null  object        \n",
      " 45  BAC_RESULT VALUE         610 non-null     float64       \n",
      " 46  CRASH_DATE_EST_I         31792 non-null   object        \n",
      " 47  POSTED_SPEED_LIMIT       523717 non-null  int64         \n",
      " 48  TRAFFIC_CONTROL_DEVICE   523717 non-null  object        \n",
      " 49  DEVICE_CONDITION         523717 non-null  object        \n",
      " 50  WEATHER_CONDITION        523717 non-null  object        \n",
      " 51  LIGHTING_CONDITION       523717 non-null  object        \n",
      " 52  FIRST_CRASH_TYPE         523717 non-null  object        \n",
      " 53  TRAFFICWAY_TYPE          523717 non-null  object        \n",
      " 54  ALIGNMENT                523717 non-null  object        \n",
      " 55  ROADWAY_SURFACE_COND     523717 non-null  object        \n",
      " 56  ROAD_DEFECT              523717 non-null  object        \n",
      " 57  CRASH_TYPE               523717 non-null  object        \n",
      " 58  INTERSECTION_RELATED_I   140362 non-null  object        \n",
      " 59  HIT_AND_RUN_I            165388 non-null  object        \n",
      " 60  DAMAGE                   523717 non-null  object        \n",
      " 61  PRIM_CONTRIBUTORY_CAUSE  523717 non-null  object        \n",
      " 62  SEC_CONTRIBUTORY_CAUSE   523717 non-null  object        \n",
      " 63  STREET_NO                523717 non-null  int64         \n",
      " 64  STREET_DIRECTION         523715 non-null  object        \n",
      " 65  STREET_NAME              523717 non-null  object        \n",
      " 66  BEAT_OF_OCCURRENCE       523717 non-null  float64       \n",
      " 67  WORK_ZONE_TYPE           1737 non-null    object        \n",
      " 68  WORKERS_PRESENT_I        633 non-null     object        \n",
      " 69  NUM_UNITS                523717 non-null  int64         \n",
      " 70  MOST_SEVERE_INJURY       523717 non-null  object        \n",
      " 71  CRASH_HOUR               523717 non-null  int64         \n",
      " 72  CRASH_DAY_OF_WEEK        523717 non-null  int64         \n",
      " 73  CRASH_MONTH              523717 non-null  int64         \n",
      " 74  LATITUDE                 519247 non-null  float64       \n",
      " 75  LONGITUDE                519247 non-null  float64       \n",
      " 76  LOCATION                 519247 non-null  object        \n",
      " 77  DAMAGE_OVER_$1500        523717 non-null  int64         \n",
      " 78  BAC_TEST                 523717 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(9), object(61)\n",
      "memory usage: 319.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OVER $1,500      360020\n",
       "$501 - $1,500    120416\n",
       "$500 OR LESS      43281\n",
       "Name: DAMAGE, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values in Damage column\n",
    "\n",
    "df['DAMAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to identify damage as > $1500 or <= $1500\n",
    "\n",
    "damage_dict = {'OVER $1,500':1, '$501 - $1,500':0, '$500 OR LESS':0}\n",
    "df['DAMAGE_OVER_$1500'] =  df.loc[:, ('DAMAGE')].map(damage_dict).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    360020\n",
       "0    163697\n",
       "Name: DAMAGE_OVER_$1500, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df['DAMAGE_OVER_$1500'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to identify BAC_TEST as Y/N\n",
    "\n",
    "bac_dict = {'TEST NOT OFFERED':0, 'TEST REFUSED':1, 'TEST PERFORMED, RESULTS UNKNOWN':1, 'TEST TAKEN':1}\n",
    "df['BAC_TEST'] =  df.loc[:, ('BAC_RESULT')].map(bac_dict).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    516361\n",
       "1      7356\n",
       "Name: BAC_TEST, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "df[\"BAC_TEST\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"DAMAGE_OVER_$1500\"], axis=1)\n",
    "y = df[\"DAMAGE_OVER_$1500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68784847, 0.68784847, 0.68785722, 0.6878445 , 0.6878445 ])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_dummy = cross_val_score(dummy_model, X_train, y_train, cv=5)\n",
    "cv_results_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Numeric Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide Xs/y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a baseline model, we will use only the already numeric columns as Xs to predict DAMAGE_OVER_$1500 as y. We will omit all columns that are simply identifiers or keys. We also omit NUM_PASSENGERS as it is directly related to OCCUPANT_CNT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NUM_PASSENGERS</th>\n",
       "      <th>VEHICLE_YEAR</th>\n",
       "      <th>OCCUPANT_CNT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BAC_RESULT VALUE</th>\n",
       "      <th>POSTED_SPEED_LIMIT</th>\n",
       "      <th>STREET_NO</th>\n",
       "      <th>BEAT_OF_OCCURRENCE</th>\n",
       "      <th>NUM_UNITS</th>\n",
       "      <th>CRASH_HOUR</th>\n",
       "      <th>CRASH_DAY_OF_WEEK</th>\n",
       "      <th>CRASH_MONTH</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DAMAGE_OVER_$1500</th>\n",
       "      <th>BAC_TEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>523717.000000</td>\n",
       "      <td>84450.000000</td>\n",
       "      <td>428682.000000</td>\n",
       "      <td>523496.000000</td>\n",
       "      <td>371575.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.00000</td>\n",
       "      <td>519247.000000</td>\n",
       "      <td>519247.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "      <td>523717.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>389995.012490</td>\n",
       "      <td>1.456945</td>\n",
       "      <td>2014.883128</td>\n",
       "      <td>1.234516</td>\n",
       "      <td>39.925474</td>\n",
       "      <td>0.175885</td>\n",
       "      <td>28.965458</td>\n",
       "      <td>3746.654508</td>\n",
       "      <td>1239.549677</td>\n",
       "      <td>2.091479</td>\n",
       "      <td>13.360557</td>\n",
       "      <td>4.137664</td>\n",
       "      <td>6.42281</td>\n",
       "      <td>41.852148</td>\n",
       "      <td>-87.673290</td>\n",
       "      <td>0.687432</td>\n",
       "      <td>0.014046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>222581.925857</td>\n",
       "      <td>0.995520</td>\n",
       "      <td>118.634721</td>\n",
       "      <td>0.667260</td>\n",
       "      <td>15.843725</td>\n",
       "      <td>0.104812</td>\n",
       "      <td>5.312512</td>\n",
       "      <td>2852.738278</td>\n",
       "      <td>701.016896</td>\n",
       "      <td>0.485050</td>\n",
       "      <td>5.512825</td>\n",
       "      <td>1.982557</td>\n",
       "      <td>3.24658</td>\n",
       "      <td>0.368367</td>\n",
       "      <td>0.752426</td>\n",
       "      <td>0.463540</td>\n",
       "      <td>0.117680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-87.936193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>195000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>715.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>41.779949</td>\n",
       "      <td>-87.722859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>396756.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>41.871981</td>\n",
       "      <td>-87.675525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>582781.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5611.000000</td>\n",
       "      <td>1814.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>41.924092</td>\n",
       "      <td>-87.633793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>766594.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>13799.000000</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>42.022780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  NUM_PASSENGERS   VEHICLE_YEAR   OCCUPANT_CNT  \\\n",
       "count  523717.000000    84450.000000  428682.000000  523496.000000   \n",
       "mean   389995.012490        1.456945    2014.883128       1.234516   \n",
       "std    222581.925857        0.995520     118.634721       0.667260   \n",
       "min         0.000000        1.000000    1900.000000       0.000000   \n",
       "25%    195000.000000        1.000000    2009.000000       1.000000   \n",
       "50%    396756.000000        1.000000    2014.000000       1.000000   \n",
       "75%    582781.000000        2.000000    2018.000000       1.000000   \n",
       "max    766594.000000       46.000000    9999.000000      47.000000   \n",
       "\n",
       "                 AGE  BAC_RESULT VALUE  POSTED_SPEED_LIMIT      STREET_NO  \\\n",
       "count  371575.000000        610.000000       523717.000000  523717.000000   \n",
       "mean       39.925474          0.175885           28.965458    3746.654508   \n",
       "std        15.843725          0.104812            5.312512    2852.738278   \n",
       "min         0.000000          0.000000            0.000000       0.000000   \n",
       "25%        27.000000          0.130000           30.000000    1329.000000   \n",
       "50%        37.000000          0.180000           30.000000    3299.000000   \n",
       "75%        51.000000          0.220000           30.000000    5611.000000   \n",
       "max       110.000000          1.000000           70.000000   13799.000000   \n",
       "\n",
       "       BEAT_OF_OCCURRENCE      NUM_UNITS     CRASH_HOUR  CRASH_DAY_OF_WEEK  \\\n",
       "count       523717.000000  523717.000000  523717.000000      523717.000000   \n",
       "mean          1239.549677       2.091479      13.360557           4.137664   \n",
       "std            701.016896       0.485050       5.512825           1.982557   \n",
       "min            111.000000       1.000000       0.000000           1.000000   \n",
       "25%            715.000000       2.000000      10.000000           2.000000   \n",
       "50%           1134.000000       2.000000      14.000000           4.000000   \n",
       "75%           1814.000000       2.000000      17.000000           6.000000   \n",
       "max           6100.000000      18.000000      23.000000           7.000000   \n",
       "\n",
       "        CRASH_MONTH       LATITUDE      LONGITUDE  DAMAGE_OVER_$1500  \\\n",
       "count  523717.00000  519247.000000  519247.000000      523717.000000   \n",
       "mean        6.42281      41.852148     -87.673290           0.687432   \n",
       "std         3.24658       0.368367       0.752426           0.463540   \n",
       "min         1.00000       0.000000     -87.936193           0.000000   \n",
       "25%         4.00000      41.779949     -87.722859           0.000000   \n",
       "50%         6.00000      41.871981     -87.675525           1.000000   \n",
       "75%         9.00000      41.924092     -87.633793           1.000000   \n",
       "max        12.00000      42.022780       0.000000           1.000000   \n",
       "\n",
       "            BAC_TEST  \n",
       "count  523717.000000  \n",
       "mean        0.014046  \n",
       "std         0.117680  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using .describe to see the variables that are already numeric\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a baseline dataframe \n",
    "\n",
    "df_bl = df[[\"VEHICLE_YEAR\", \"OCCUPANT_CNT\", \"AGE\", \"BAC_RESULT VALUE\", \"POSTED_SPEED_LIMIT\", \"STREET_NO\", \"BEAT_OF_OCCURRENCE\", \"NUM_UNITS\", \"CRASH_HOUR\", \"CRASH_DAY_OF_WEEK\", \"CRASH_MONTH\", \"LATITUDE\", \"LONGITUDE\", \"BAC_TEST\", \"DAMAGE_OVER_$1500\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning Xs & y \n",
    "\n",
    "X_bl = df_bl.drop(\"DAMAGE_OVER_$1500\", axis=1)\n",
    "y_bl = df[\"DAMAGE_OVER_$1500\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bl, X_test_bl, y_train_bl, y_test_bl = train_test_split(X_bl, y_bl, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps (SS, OHE, SI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer()\n",
    "X_train_blimp = numeric_imputer.fit_transform(X_train_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (look at Coefficients, P-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_logreg = LogisticRegression(random_state=2024, penalty=\"none\", max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, penalty='none', random_state=2024)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_logreg.fit(X_train_blimp, y_train_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   297, 122312],\n",
       "       [   396, 269782]], dtype=int64)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_bl, bl_logreg.predict(X_train_blimp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68652461, 0.68769572, 0.68640605, 0.68739896, 0.68660972])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_val_score(bl_logreg, X_train_blimp, y_train_bl, cv=5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model CV:           [0.68784847 0.68784847 0.68785722 0.6878445  0.6878445 ]\n",
      "Initial Numeric Model CV: [0.68652461 0.68769572 0.68640605 0.68739896 0.68660972]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dummy Model CV:          \", cv_results_dummy)\n",
    "print(\"Initial Numeric Model CV:\", cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that a model using only the columns which are already numeric is only as good as picking the most frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation OF/UF report Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
